{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# alternative: read file into Pandas using a relative path\n",
    "path = '../data/yelp.csv'\n",
    "# Task 1: read the data\n",
    "ylp = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the read data\n",
    "ylp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 2: Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "ylp = ylp[(ylp['stars'] == 5) | (ylp['stars'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IJ0o6b8bJFAbG6MjGfBebQ</td>\n",
       "      <td>2010-09-05</td>\n",
       "      <td>Dx9sfFU6Zn0GYOckijom-g</td>\n",
       "      <td>1</td>\n",
       "      <td>U can go there n check the car out. If u wanna...</td>\n",
       "      <td>review</td>\n",
       "      <td>zRlQEDYd_HKp0VS3hnAffA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id        date               review_id  stars  \\\n",
       "23  IJ0o6b8bJFAbG6MjGfBebQ  2010-09-05  Dx9sfFU6Zn0GYOckijom-g      1   \n",
       "\n",
       "                                                 text    type  \\\n",
       "23  U can go there n check the car out. If u wanna...  review   \n",
       "\n",
       "                   user_id  cool  useful  funny  \n",
       "23  zRlQEDYd_HKp0VS3hnAffA     0       1      1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylp[(ylp['stars'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylp[(ylp['stars'] == 5)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [business_id, date, review_id, stars, text, type, user_id, cool, useful, funny]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylp[(ylp['stars'] == 4)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 3: create X and y\n",
    "X = ylp.text\n",
    "y = ylp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task4: import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task5: import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91878669275929548"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  58],\n",
       "       [ 25, 813]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task6: calculate the null accuracy\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199608610567515"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent class is 5, calculate null accuracy for class 5\n",
    "float(y_test.value_counts()[5]) / sum(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 7\n",
    "# visualize class 1 which were incorrectly predicted as class 5 (False positive)\n",
    "X_test[y_test < y_pred_class][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This has to be the worst restaurant in terms of hygiene. Two of my friends had food -poisoning after having dinner here. The food is just unhealthy with tons of oil floating on the top of curries, and I am not sure if any health/hygiene code is followed here. \\nThe service is poor and the information on its website is incorrect, the owner does not allow dine-in after 9 or 10 even though it says that the restaurant is open till 11. \\n\\nOne night I saw the owner cleaning the place without gloves and she was nice enough to give us a to-go parcel without cleaning her hands (great example to the servers!). I had a peek inside the kitchen when the door was ajar, and it definitely looked dirty.\\n\\nI have been a lot of hole-in-the-wall places around this restaurant, including Haji Baba, the Vietnamese place and others, but neither any of my friends nor I have fallen sick coz of the food. If you need a spicy-food fix, i strongly recommend you do not try this place, lest you want a visit to the doctor the very next day.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[y_test < y_pred_class][2175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize class 5 which were incorrectly predicted as class 1 (False negative)\n",
    "X_test[y_test > y_pred_class][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I now consider myself an Arizonian. If you drive a lot on the 101 or 51 like I do, you'll get your fair share of chips on your windshield. You'll also have to replace a windshield like I had to do just recently. Apparently, chips and cracking windshields  is common in Arizona. In fact, I seem to recall my insurance agent telling me that insurance companies must provide this coverage in Arizona.\\n\\nI had a chip repaired about a year ago near the very bottom of the windshield. Just recently a small, very fine crack started traveling north on the windshield from the repaired chip (a different vendor repaired the chip). I called these guys over to my house and they said it was too long to fix, so they replaced the whole windshield the next day.\\n\\nWhat great service, they come out to your residence or place of business to repair or replace your windshield.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[y_test > y_pred_class][7148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# False positive: Even though the review for the restaurant was bad, it was predicted as being good\n",
    "# False negative: A review that actually should inspire people to go to the restaurant was predicted as being bad\n",
    "\n",
    "# Both FP & FN reviews are long and therefore most certainly contain a lot of words considered as being 'good' by NB\n",
    "# as well as words considered to be 'bad'. Like learned in the class a 'positiviness' of each word can be calculate to\n",
    "# visualize what NB thinks how positive specific words are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across messages with low rating (bad) [1 star]\n",
    "bad_token_count = nb.feature_count_[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across messages with high rating (good) [5 star]\n",
    "good_token_count = nb.feature_count_[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate good and bad counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'bad':bad_token_count, 'good':good_token_count}).set_index('token')\n",
    "\n",
    "tokens['bad'] = tokens.bad + 1\n",
    "tokens['good'] = tokens.good + 1\n",
    "tokens['bad'] = tokens.bad / nb.class_count_[0]\n",
    "tokens['good'] = tokens.good / nb.class_count_[1]\n",
    "\n",
    "tokens['positiveness'] = tokens.good / tokens.bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>positiveness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazed</th>\n",
       "      <td>0.00177</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>2.939176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polytechnic</th>\n",
       "      <td>0.00177</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.452181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheared</th>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.113045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impersonal</th>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.113045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sane</th>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.113045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bad      good  positiveness\n",
       "token                                       \n",
       "amazed       0.00177  0.005202      2.939176\n",
       "polytechnic  0.00177  0.000800      0.452181\n",
       "sheared      0.00354  0.000400      0.113045\n",
       "impersonal   0.00354  0.000400      0.113045\n",
       "sane         0.00354  0.000400      0.113045"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'you', u'worst', u'without', u'with', u'when', u'website', u'was', u'want', u'wall', u'visit', u'vietnamese', u'very', u'us', u'two', u'try', u'top', u'tons', u'to', u'till', u'though', u'this', u'the', u'that', u'terms', u'sure', u'strongly', u'spicy', u'sick', u'she', u'service', u'servers', u'says', u'saw', u'restaurant', u'recommend', u'poor', u'poisoning', u'places', u'place', u'peek', u'owner', u'others', u'or', u'open', u'one', u'on', u'oil', u'of', u'not', u'nor', u'night', u'nice', u'next', u'neither', u'need', u'my', u'lot', u'looked', u'kitchen', u'just', u'its', u'it', u'is', u'inside', u'information', u'incorrect', u'including', u'in', u'if', u'hygiene', u'hole', u'here', u'her', u'health', u'having', u'have', u'has', u'hands', u'haji', u'had', u'great', u'go', u'gloves', u'give', u'friends', u'food', u'followed', u'floating', u'fix', u'fallen', u'example', u'even', u'enough', u'door', u'does', u'doctor', u'do', u'dirty', u'dinner', u'dine', u'definitely', u'day', u'curries', u'coz', u'code', u'cleaning', u'but', u'been', u'be', u'baba', u'around', u'any', u'and', u'am', u'allow', u'after', u'11', u'10']\n"
     ]
    }
   ],
   "source": [
    "fp_tokens = vect.inverse_transform(X_test_dtm[(y_test < y_pred_class).values][0])[0].tolist()\n",
    "print(fp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in FP with positivness > 1 = 28 | sum(positivness) = 43.5417671655 \n",
      "Words in FP with positivness < 1 = 90 | sum(positivness) = 52.5077953898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# I do not exactly know how NB works but for the FP mentioned above the positivness for the positive and negative tokens\n",
    "# is in the same range if summed up\n",
    "\n",
    "# I did this to help me see why NB would misclassify the fp. But I do not fully understand the results. \n",
    "# What can be observed here is that there are very few positive words (28) but the positivity is very high.\n",
    "print(\"Words in FP with positivness > 1 =\", len(tokens.loc[fp_tokens][(tokens['positiveness'] > 1)]),\n",
    "      \"| sum(positivness) =\", sum(tokens.loc[fp_tokens][(tokens['positiveness'] > 1)].positiveness),\n",
    "      \"\\nWords in FP with positivness < 1 =\", len(tokens.loc[fp_tokens][(tokens['positiveness'] < 1)]),\n",
    "      \"| sum(positivness) =\", sum(tokens.loc[fp_tokens][(tokens['positiveness'] < 1)].positiveness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'your', u'you', u'year', u'windshield', u'whole', u'what', u'was', u'very', u'vendor', u'traveling', u'too', u'to', u'this', u'they', u'these', u'the', u'that', u'telling', u'started', u'so', u'small', u'share', u'service', u'seem', u'said', u'residence', u'replaced', u'replace', u'repaired', u'repair', u'recently', u'recall', u'provide', u'place', u'over', u'out', u'or', u'on', u'of', u'now', u'north', u'next', u'near', u'myself', u'my', u'must', u'me', u'lot', u'long', u'll', u'like', u'just', u'it', u'is', u'insurance', u'in', u'if', u'house', u'have', u'had', u'guys', u'great', u'get', u'from', u'fix', u'fine', u'fair', u'fact', u'drive', u'do', u'different', u'day', u'cracking', u'crack', u'coverage', u'consider', u'companies', u'common', u'come', u'chips', u'chip', u'called', u'business', u'bottom', u'arizona', u'apparently', u'and', u'an', u'also', u'ago', u'agent', u'about', u'51', u'101']\n"
     ]
    }
   ],
   "source": [
    "fn_tokens = vect.inverse_transform(X_test_dtm[(y_test > y_pred_class).values][0])[0].tolist()\n",
    "print(fn_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in FN with positivness > 1 = 18 | sum(positivness) = 27.1616718046 \n",
      "Words in FN with positivness < 1 = 76 | sum(positivness) = 46.2806494764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/tbottesch/.virtualenvs/MLText/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "print(\"Words in FN with positivness > 1 =\", len(tokens.loc[fn_tokens][(tokens['positiveness'] > 1)]),\n",
    "      \"| sum(positivness) =\", sum(tokens.loc[fn_tokens][(tokens['positiveness'] > 1)].positiveness),\n",
    "      \"\\nWords in FN with positivness < 1 =\", len(tokens.loc[fn_tokens][(tokens['positiveness'] < 1)]),\n",
    "      \"| sum(positivness) =\", sum(tokens.loc[fn_tokens][(tokens['positiveness'] < 1)].positiveness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>positiveness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>21.817727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>18.464052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>14.017607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.138055</td>\n",
       "      <td>11.143029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outstanding</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>11.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brunch</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>9.495798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.016006</td>\n",
       "      <td>9.043617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>8.817527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>8.817527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.185274</td>\n",
       "      <td>8.723323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bad      good  positiveness\n",
       "token                                        \n",
       "fantastic    0.003540  0.077231     21.817727\n",
       "perfect      0.005310  0.098039     18.464052\n",
       "yum          0.001770  0.024810     14.017607\n",
       "favorite     0.012389  0.138055     11.143029\n",
       "outstanding  0.001770  0.019608     11.078431\n",
       "brunch       0.001770  0.016807      9.495798\n",
       "gem          0.001770  0.016006      9.043617\n",
       "mozzarella   0.001770  0.015606      8.817527\n",
       "pasty        0.001770  0.015606      8.817527\n",
       "amazing      0.021239  0.185274      8.723323"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 8:\n",
    "tokens.sort_values(\"positiveness\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>positiveness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staffperson</th>\n",
       "      <td>0.030088</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.013299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refused</th>\n",
       "      <td>0.024779</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.016149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>0.042478</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.018841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filthy</th>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.020554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unprofessional</th>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.025121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.025121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledge</th>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.025121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>0.030088</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.026599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuse</th>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.028261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boca</th>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.028261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bad    good  positiveness\n",
       "token                                         \n",
       "staffperson     0.030088  0.0004      0.013299\n",
       "refused         0.024779  0.0004      0.016149\n",
       "disgusting      0.042478  0.0008      0.018841\n",
       "filthy          0.019469  0.0004      0.020554\n",
       "unprofessional  0.015929  0.0004      0.025121\n",
       "unacceptable    0.015929  0.0004      0.025121\n",
       "acknowledge     0.015929  0.0004      0.025121\n",
       "ugh             0.030088  0.0008      0.026599\n",
       "fuse            0.014159  0.0004      0.028261\n",
       "boca            0.014159  0.0004      0.028261"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values(\"positiveness\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 9\n",
    "ylp = pd.read_csv(path)\n",
    "# Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "X = ylp.text\n",
    "y = ylp.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create document-term matrices using CountVectorizer.\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47120000000000001"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    884\n",
       "5    832\n",
       "3    365\n",
       "2    234\n",
       "1    185\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3536"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent class is 4, calculate null accuracy for class 4\n",
    "float(y_test.value_counts()[4]) / sum(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overall accuracy decreased which makes sense since separating 5 classes from each other\n",
    "# is harder than separating only two. I would expect that classes (1 and 2, 2 and 3 ...) next to each other\n",
    "# are often confused with each other.\n",
    "\n",
    "# Regarding the null accuracy. Class 4 and 5 have almost equal size and 'own' together ~70% of the dataset\n",
    "# If both classes would have perfect predictions we would see an accuracy of 0.7. This is not the case which\n",
    "# makes one assume that both classes are often confused with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55,  14,  24,  65,  27],\n",
       "       [ 28,  16,  41, 122,  27],\n",
       "       [  5,   7,  35, 281,  37],\n",
       "       [  7,   0,  16, 629, 232],\n",
       "       [  6,   4,   6, 373, 443]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# like expected class 4 and 5 are often confused\n",
    "# same for 1 and 2\n",
    "# it is very strange that so many samples which are actually 2 star ratings are confused with 4 star ratings (122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 star        0.54      0.30      0.38       185\n",
      "    2 stars       0.39      0.07      0.12       234\n",
      "    3 stars       0.29      0.10      0.14       365\n",
      "    4 stars       0.43      0.71      0.53       884\n",
      "    5 stars       0.58      0.53      0.55       832\n",
      "\n",
      "avg / total       0.46      0.47      0.43      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['1 star ', '2 stars', '3 stars', '4 stars', '5 stars']\n",
    "\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The recall score of 2 stars shows that many ratings with != 2 stars are predicted as having 2 stars\n",
    "# The recall score of 3 stars shows that many ratings with != 3 stars are predicted as having 3 stars\n",
    "\n",
    "# Many ratings are predicted to be have a 4 star rating while they actually have a different rating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
